{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Four: Contingency tables and External Resources\n",
    "This notebook will take a look at everything you have learned so far, from cleaning data, to creating contingency tables, to other visualisations you can create!\n",
    "\n",
    "If you wish to learn more, we have also included some suggestions and links to other resources that you could utilise to further devlop either your Python or general programming skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/chroadhouse/Futureme/main/Data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data has imported correctly\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before looking at contingency tables you many want to create some custom tables with more than one column\n",
    "# We can do this by creating two separate tables and then merging the data\n",
    "age_mean = data['Age'].mean()\n",
    "age_mode = data['Age'].mode()\n",
    "age_median = data['Age'].median()\n",
    "age_max = data['Age'].max()\n",
    "age_min = data['Age'].min()\n",
    "age_stand = data['Age'].std()\n",
    "\n",
    "age_table = pd.DataFrame({\n",
    "    'Mean':age_mean,\n",
    "    'Mode':age_mode,\n",
    "    'Median':age_median,\n",
    "    'Maximum':age_max,\n",
    "    'Minumum':age_min,\n",
    "    'Standard Deviation':age_stand\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "fare_mean = data['Fare'].mean()\n",
    "fare_mode = data['Fare'].mode()\n",
    "fare_median = data['Fare'].median()\n",
    "fare_max = data['Fare'].max()\n",
    "fare_min = data['Fare'].min()\n",
    "fare_stand = data['Fare'].std()\n",
    "\n",
    "\n",
    "fare_table = pd.DataFrame({\n",
    "    'Mean':fare_mean,\n",
    "    'Mode':fare_mode,\n",
    "    'Median':fare_median,\n",
    "    'Maximum':fare_max,\n",
    "    'Minumum':fare_min,\n",
    "    'Standard Deviation':fare_stand\n",
    "})\n",
    "\n",
    "# We can now combine these two tables together to make the data more managable to look at - run this cell and see how it looks!\n",
    "\n",
    "combined_table = pd.DataFrame({\n",
    "    'Type':['Age', 'Ticket Fare'],\n",
    "    'Mean':[age_mean, fare_mean],\n",
    "    'Mode':[age_mode[0], fare_mode[0]],\n",
    "    'Median':[age_median, fare_median],\n",
    "    'Maximum':[age_max, fare_max],\n",
    "    'Minumum':[age_min, fare_min],\n",
    "    'Standard Deviation':[age_stand, fare_stand]\n",
    "}).set_index('Type')\n",
    "\n",
    " \n",
    "combined_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contingency Tables\n",
    "Remember - we generally use contingency tables when we want to observe relationships between categorical data.\n",
    "\n",
    "Do do this, however, we need to make sure the data is **'clean'**.\n",
    "\n",
    "If you need to remind yourself in more detail about this, you can always go back to the exercises for Day 3. You don't need to do this from sctratch as we have filled in these cells for you, but you do need to know **why** it's important.\n",
    "\n",
    "Once you know **how** these visualisations can help you make conclusions about the data, you can start thinking about the historical significance of what it actually tells you. We have included some questions in the cells below to kickstart your thinking on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to clean the data on age and cabin categories \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get the value for where most people embarked \n",
    "# Why do you think more people got on the ship at Southamption, rather than Cherbourg or Queenstown?\n",
    "data['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we fill in the columns with the averages of the data\n",
    "data['Age'] = data['Age'].replace(np.nan, data['Age'].mean())\n",
    "data['Embarked'] = data['Embarked'].fillna('S')\n",
    "\n",
    "data = data.drop(columns=['Cabin'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we create a contingency table to show the males and females that did and didn't survive\n",
    "pd.crosstab(data.Sex, data.Survived, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also have a contingency table showing percentages \n",
    "# Have a think about what this table shows you - why do you think more women survived than men?\n",
    "pd.crosstab(data.Sex, data.Survived, margins=True, normalize='index').round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert some continuous data to categorical to see more relationships.\n",
    "data['Age'] = pd.cut(data['Age'],bins=[0,17,65,99],labels=['Child','Adult','Elder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then plot this converted age data against which port they embarked on.\n",
    "# Why do you think so few elderly people were on the Titanic?\n",
    "pd.crosstab(data.Age, data.Embarked, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrernal resources \n",
    "If you have enjoyed this brief introduction to Python for data analysis, you should consider broadening your knowledge on the subject. In a society that is placing more and more emphasis on digital skills, Python in particular is a brilliantly versatile one to have on your CV, showing:\n",
    "   * Your ability to solve problems\n",
    "   * Digital fluency\n",
    "   * Your motivation to learn\n",
    "\n",
    "Programming and computer science is one of the main subjects that has a large number of detailed resources to help you learn and develop. Some of these resources even provide certificates as proof of your capability in programming.\n",
    "* FreeCodeCamp -  https://www.freecodecamp.org - Provides easy and intuative courses with certificates to give credit for course completion offering courses such as:\n",
    "    - Web development\n",
    "    - Data Analysis using python \n",
    "    - Scientific computing using python \n",
    "    - Machine Learning (AI) using python \n",
    "    - Algorithms and Data structures in Javascript \n",
    "\n",
    "* Linkedin Learning - All MMU students have free access to LinkedIn Learning. It provides video courses and certificates linked to your LinkedIn account (this also automatically earns you Rise points too)!\n",
    "\n",
    "* CS Dojo - Videos on Youtube that provide multiple resources aimed at beginners to try and encourage coding.\n",
    "\n",
    "* Rise - It's also a good idea to keep an eye on the Rise website, as new courses are being added all the time. Currently, you can sign up for Python for Scientific Computing and TensorFlow for Artificial Intelligence with Stephen Lynch: https://rise.mmu.ac.uk/activity/python-for-scientific-computing-and-tensorflow-for-artificial-intelligence-3/\n",
    "\n",
    "* Or you could also preorder Stephen Lynch's book, which is centered around Python for Artificial Intelligence and Scientific Computing: https://www.routledge.com/Python-for-Scientific-Computing-and-Artificial-Intelligence/Lynch/p/book/9781032258713#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0df3d53152e8e130235b46b9046afba8add0a5c5c7db06a775ee0d5f1d3271b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
